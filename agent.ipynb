{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.openai_agent import create_agent\n",
    "from modules.chat_history import ChatHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "# get_word_length.invoke(\"abc\")\n",
    "\n",
    "tools = [get_word_length, TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "chat = ChatHistory(\"Welcome to the chat!\")\n",
    "agent = create_agent(prompt=prompt, tools=tools, chat=chat)\n",
    "model = create_agent(tools=tools, model_only=True, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is langraph?',\n",
       " 'chat_history': [SystemMessage(content='Welcome to the chat!'),\n",
       "  HumanMessage(content='What is langraph?'),\n",
       "  AIMessage(content='LangGraph is a new package available in both Python and JavaScript that enables the creation of LLM (LangChain Language Model) workflows containing cycles, which are a critical component of most agent runtimes. It is fully integrated into the LangChain ecosystem, allowing users to take full advantage of all the LangChain integrations and LangSmith observability. LangGraph is designed to facilitate multi-agent workflows and has been used to build applications that utilize the concept of multiple agents. You can find more information about LangGraph in this [blog post](https://blog.langchain.dev/langgraph-multi-agent-workflows/).')],\n",
       " 'output': 'LangGraph is a new package available in both Python and JavaScript that enables the creation of LLM (LangChain Language Model) workflows containing cycles, which are a critical component of most agent runtimes. It is fully integrated into the LangChain ecosystem, allowing users to take full advantage of all the LangChain integrations and LangSmith observability. LangGraph is designed to facilitate multi-agent workflows and has been used to build applications that utilize the concept of multiple agents. You can find more information about LangGraph in this [blog post](https://blog.langchain.dev/langgraph-multi-agent-workflows/).'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"What is langraph?\"\n",
    "agent.invoke({\"input\": user_input, \"chat_history\": chat.history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_I5iCBbxbAftTyFq7B4v8IZ1j', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"Weather in San Francisco is {\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1708570265, \\'localtime\\': \\'2024-02-21 18:51\\'}, \\'current\\': {\\'last_updated_epoch\\': 1708569900, \\'last_updated\\': \\'2024-02-21 18:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 8.1, \\'wind_kph\\': 13.0, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.21, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 80, \\'cloud\\': 75, \\'feelslike_c\\': 12.1, \\'feelslike_f\\': 53.8, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 11.8, \\'gust_kph\\': 18.9}}\"}]', tool_call_id='call_I5iCBbxbAftTyFq7B4v8IZ1j')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 13.3째C (55.9째F). The wind speed is 13.0 kph from the west, and the humidity is at 80%.')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node '__end__':\n",
      "---\n",
      "{'messages': [HumanMessage(content='what is the weather in sf'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_I5iCBbxbAftTyFq7B4v8IZ1j', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"Weather in San Francisco is {\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1708570265, \\'localtime\\': \\'2024-02-21 18:51\\'}, \\'current\\': {\\'last_updated_epoch\\': 1708569900, \\'last_updated\\': \\'2024-02-21 18:45\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 8.1, \\'wind_kph\\': 13.0, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.21, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 80, \\'cloud\\': 75, \\'feelslike_c\\': 12.1, \\'feelslike_f\\': 53.8, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 11.8, \\'gust_kph\\': 18.9}}\"}]', tool_call_id='call_I5iCBbxbAftTyFq7B4v8IZ1j'), AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 13.3째C (55.9째F). The wind speed is 13.0 kph from the west, and the humidity is at 80%.')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolInvocation, ToolExecutor\n",
    "from langchain_core.messages import ToolMessage\n",
    "import json\n",
    "from modules.create_graph import create_graph, stream_app\n",
    "\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "tool_indicator = \"tool_calls\" #\"function_call\"\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if tool_indicator not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_agent(state):\n",
    "    messages = state['messages']\n",
    "    response = agent.invoke(\n",
    "        {\"input\": messages[0], \"chat_history\": chat.history})\n",
    "    return {\"messages\": [response['output']]}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool = last_message.additional_kwargs[tool_indicator][0]\n",
    "    action = ToolInvocation(\n",
    "        tool=tool['function'][\"name\"],\n",
    "        tool_input=json.loads(tool['function']['arguments'])\n",
    "    )\n",
    "\n",
    "    response = tool_executor.invoke(action)\n",
    "    function_message = ToolMessage(content=str(response), tool_call_id=tool['id'])\n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "\n",
    "nodes = [{\"name\": \"agent\", \"node\": call_model}, {\n",
    "    \"name\": \"action\", \"node\": call_tool, \"condition\": should_continue}]\n",
    "\n",
    "app = create_graph(nodes)\n",
    "\n",
    "user_input = \"what is the weather in sf\"\n",
    "stream_app(app, user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
